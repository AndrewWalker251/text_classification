{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.data import Field,LabelField\n",
    "from torchtext.data import Example\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by :\n",
    "    https://www.kaggle.com/swarnabha/pytorch-text-classification-torchtext-lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy = spacy.load(\"en_core_web_sm\")\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# can't get spacy to work. \n",
    "# How do we get it so we can get rid of puntuation and stuff\n",
    "# Make sure you get rid of stop words somewhere. \n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "#tokens = tokenizer(df['text'][1])\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>\\t\\t\\tCrouching Tiger, Hidden Dragon\\n\\n\\t\\t\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>\"MUMFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>MAX PAYNE\\n\\n          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>SLUMDOG MILLIONAIRE\\n\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>&lt;b&gt;&lt;!--\\n\\n&lt;/b&gt;if (window!= top)\\n\\ntop.locati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>THE OTHER BOLEYN GIR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>GET CARTER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>CRAZY, STUPID, LOV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>TRISTAN + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>BADLANDS\\n\\nby Terence Malick\\n\\nFinal Version...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       8  \\t\\t\\tCrouching Tiger, Hidden Dragon\\n\\n\\t\\t\\t...\n",
       "1       4                                          \"MUMFO...\n",
       "2       6                         MAX PAYNE\\n\\n          ...\n",
       "3       6                        SLUMDOG MILLIONAIRE\\n\\n ...\n",
       "4      16  <b><!--\\n\\n</b>if (window!= top)\\n\\ntop.locati...\n",
       "5      15                            THE OTHER BOLEYN GIR...\n",
       "6      19                                      GET CARTER...\n",
       "7      15                              CRAZY, STUPID, LOV...\n",
       "8       1                                      TRISTAN + ...\n",
       "9       6  BADLANDS\\n\\nby Terence Malick\\n\\nFinal Version..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"torchtext_data/train.csv\")\n",
    "df = df.rename(columns = {'Script':'text','Labels':'target'})\n",
    "df = df[0:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete some basic text cleaning.\n",
    "# to clean data\n",
    "def normalise_text (text):\n",
    "    text = text.str.lower() # lowercase\n",
    "    text = text.str.replace(r\"\\#\",\"\") # replaces hashtags\n",
    "    text = text.str.replace(r\"http\\S+\",\"URL\")  # remove URL addresses\n",
    "    text = text.str.replace(r\"@\",\"\")\n",
    "    text = text.str.replace(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\", \" \")\n",
    "    text = text.str.replace(\"\\s{2,}\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = normalise_text(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = \"spacy\" uses spacy's tokenizer\n",
    "# Option to add in sequential = True here. Look into this. \n",
    "TEXT = Field(tokenize=tokenizer, include_lengths = True)\n",
    "LABEL = LabelField(dtype=torch.long, sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    # Do we need to add one example at a time.\n",
    "    fields = [('text',TEXT),('label', LABEL)]\n",
    "    examples_prep = []\n",
    "    for i, row in df.iterrows():\n",
    "        label = row.target\n",
    "        text = row.text\n",
    "        examples_prep.append(Example.fromlist([text,label], fields))\n",
    "\n",
    "    dataset_output = torchtext.data.Dataset(examples = examples_prep, fields=fields)\n",
    "    return dataset_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(train_df)\n",
    "valid_ds = create_dataset(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check an example: \n",
    "#print(vars(pytorch_text_dataset[2]))\n",
    "#print(type(pytorch_text_dataset[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the text vocab. \n",
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_ds, max_size= MAX_VOCAB_SIZE, vectors = 'glove.6B.200d',unk_init = torch.Tensor.zero_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why do we build vocab for the label\n",
    "LABEL.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an iterator\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_ds, valid_ds), \n",
    "    batch_size = BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1056],\n",
      "        [1468],\n",
      "        [ 194],\n",
      "        ...,\n",
      "        [  26],\n",
      "        [   2],\n",
      "        [ 248]])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print((batch.text[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Iterator.data of <torchtext.data.iterator.BucketIterator object at 0x000001F6B35A3080>>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "vocab_size\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to build my model\n",
    "\n",
    "class classification_net(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embedding_dim):\n",
    "        super(classification_net, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "        nn.Embedding(vocab_size, embedding_dim),\n",
    "        nn.Linear(embedding_dim, 22),\n",
    "        nn.Softmax()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = classification_net(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1ace9763769b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-350acc71dc6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "network.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained vectors into the embedding matrix.\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "network.embedding.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
